{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA Dataset\n",
    "\n",
    "### File Characteristics\n",
    "\n",
    "img_align_celeba (sized images)\n",
    " - 202,599 images\n",
    "\n",
    "identity_CelebA\n",
    " - ALL lines: imge_id.jpg (ex. 000001.jpg) person_id\n",
    "\n",
    "list_attr_celeba\n",
    " - 1st line: number of images\n",
    " - 2nd line: Categories\n",
    " - 3rd+ lines: imge_id.jpg (ex. 000001.jpg) 1 or -1 for each category\n",
    "\n",
    "list_landmarks_align_celeba\n",
    " - 1st line: number of images\n",
    " - 2nd line: categories (ie. lefteye_x righteye_x etc)\n",
    " - 3rd_ lines: img_id.jpg (ex. 000001.jpg) number for position\n",
    "\n",
    "#### File Links\n",
    "Image Dataset: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\"\n",
    "\n",
    "Identity Annotations: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\identity_CelebA.txt\"\n",
    "\n",
    "Attribute Annoatations: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\list_attr_celeba.txt\"\n",
    "\n",
    "Landmark Location Annotations: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\list_landmarks_align_celeba.txt\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Image, Grey Scale\n",
      "(218, 178)\n",
      "[[233 233 233 ... 232 241 241]\n",
      " [233 233 233 ... 234 241 241]\n",
      " [233 233 233 ... 236 242 242]\n",
      " ...\n",
      " [ 88  63  93 ...  72  73  73]\n",
      " [ 77  85 113 ...  66  68  68]\n",
      " [115 151 192 ...  66  68  68]]\n"
     ]
    }
   ],
   "source": [
    "# Example opening one image in greyscale\n",
    "image = cv2.imread(r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\\000001.jpg\", 0)\n",
    "\n",
    "# The 2D Matrix of the image values. \n",
    "npimage = np.array(image)\n",
    "np.set_printoptions()\n",
    "print(\"First Image, Grey Scale\")\n",
    "print(np.shape(npimage))\n",
    "print(npimage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing up the dataset (Priminary)\n",
    "Total image count: 202,599\n",
    "\n",
    "Preliminary Training:   000001.jpg - 010000.jpg Count: 10,000 <br>\n",
    "\n",
    "Image dimensions 178 x 218\n",
    "\n",
    "First goal: Hat Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hat detection\n",
    "# Wearing Hat is at 35 index in second row\n",
    "# Wearing Hat is at 36 index (with first value being the ID of the image)\n",
    "# Total of 40 Attributes, Example Row:\n",
    "# ['000001.jpg' '-1' '1' '1' '-1' '-1' '-1' '-1' '-1' '-1' '-1' '-1' '1' '-1' '-1' '-1' '-1' '-1' '-1' '1' '1' '-1' '1' '-1' '-1' '1' '-1' '-1' '1' '-1' '-1' '-1' '1' '1' '-1' '1' '-1' '1' '-1' '-1' '1']\n",
    "# CSV File format\n",
    "# *     Label 1     Label 2     ...     Label n\n",
    "# imgID value 1     value 2     ...     value n\n",
    "# imgID value 1     value 2     ...     value n\n",
    "labels_csv_path = r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\list_attr_celeba_CSV.csv\"   # CSV File created with celeb attributes .txt file\n",
    "image_dataset_directory = r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\"                      # File path to image dataset\n",
    "\n",
    "# open csv and read the file names and labels\n",
    "with open(labels_csv_path, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader) # skip first header row\n",
    "\n",
    "    # Create lists to store file names and labels\n",
    "    file_names = []\n",
    "    labels = []\n",
    "\n",
    "    for i, line in enumerate(reader):\n",
    "        if i>= 20000:                   # The first 10000 values\n",
    "            break\n",
    "\n",
    "        file_name = line[0]             # 0 is where the file name is\n",
    "        label = line[36]                # 36 is where the Wearing_Hat label is\n",
    "\n",
    "        file_names.append(file_name)    # ADDING FILE NAME TO LIST\n",
    "        labels.append(label)            # ADDING LABEL TO LIST  \n",
    "\n",
    "# Load the images and the labels\n",
    "images = []\n",
    "for file_name in file_names:\n",
    "    image_path = f\"{image_dataset_directory}\\{file_name}\"\n",
    "    img = cv2.imread(image_path, 0) # Grayscale read, shouldn't need color for hat detection\n",
    "    images.append(img)\n",
    "\n",
    "images = np.array(images)\n",
    "images = images / 255.0 # Normalize to 0 to 1\n",
    "labels_pre = np.array(labels)\n",
    "labels = [1 if label == '1' else -1 for label in labels_pre] # NO string format\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Data: Images[0]: \n",
      "[[0.91372549 0.91372549 0.91372549 ... 0.90980392 0.94509804 0.94509804]\n",
      " [0.91372549 0.91372549 0.91372549 ... 0.91764706 0.94509804 0.94509804]\n",
      " [0.91372549 0.91372549 0.91372549 ... 0.9254902  0.94901961 0.94901961]\n",
      " ...\n",
      " [0.34509804 0.24705882 0.36470588 ... 0.28235294 0.28627451 0.28627451]\n",
      " [0.30196078 0.33333333 0.44313725 ... 0.25882353 0.26666667 0.26666667]\n",
      " [0.45098039 0.59215686 0.75294118 ... 0.25882353 0.26666667 0.26666667]]\n",
      "Example Data: Labels\n",
      "[-1 -1 -1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "# images --> a 10000 length list where each item is a array with gray scale values normalized 0 to 1\n",
    "# labels --> a 10000 length list where each index is 1 or -1 corresponding to images\n",
    "image_shape = np.shape(images) # (10000, 218, 178)\n",
    "label_shape = np.shape(labels) # (10000,)\n",
    "input_shape = (image_shape[1], image_shape[2], 1)\n",
    "print(\"Example Data: Images[0]: \")\n",
    "print(images[0])\n",
    "print(\"Example Data: Labels\")\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 216, 176, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 108, 88, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 106, 86, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 53, 43, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 51, 41, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 25, 20, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 32000)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                2048064   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,103,873\n",
      "Trainable params: 2,103,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create CNN Model Architecutre\n",
    "\n",
    "model = tf.keras.Sequential ([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape = (218, 178, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2,)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(images, labels, batch_size = 1, epochs = 10, validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
