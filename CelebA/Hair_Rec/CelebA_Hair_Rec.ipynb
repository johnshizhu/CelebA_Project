{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Image, Grey Scale\n",
      "(218, 178)\n",
      "[[233 233 233 ... 232 241 241]\n",
      " [233 233 233 ... 234 241 241]\n",
      " [233 233 233 ... 236 242 242]\n",
      " ...\n",
      " [ 88  63  93 ...  72  73  73]\n",
      " [ 77  85 113 ...  66  68  68]\n",
      " [115 151 192 ...  66  68  68]]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\\000001.jpg\", 0)\n",
    "\n",
    "# The 2D Matrix of the image values. \n",
    "npimage = np.array(image)\n",
    "np.set_printoptions()\n",
    "print(\"First Image, Grey Scale\")\n",
    "print(np.shape(npimage))\n",
    "print(npimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing up the dataset (Priminary)\n",
    "Total image count: 202,599\n",
    "\n",
    "Preliminary Training:   000001.jpg - 010000.jpg Count: 10,000 <br>\n",
    "\n",
    "Image dimensions 178 x 218\n",
    "\n",
    "Goal: Hair Detection\n",
    "\n",
    "Based on the \"Bald\" Annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimages --> all images as grayscale in matrix format\\nlabels --> all labels as 0 for bald and 1 for hair\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_csv_path = r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\list_attr_celeba_CSV.csv\"   # CSV File created with celeb attributes .txt file\n",
    "image_dataset_directory = r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\"                      # File path to image dataset\n",
    "\n",
    "# open csv and read the file names and labels\n",
    "with open(labels_csv_path, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader) # skip first header row\n",
    "\n",
    "    # Create lists to store file names and labels\n",
    "    file_names = []\n",
    "    labels = []\n",
    "\n",
    "    for i, line in enumerate(reader):\n",
    "        if i>= 20000:                   # The first 10000 values\n",
    "            break\n",
    "\n",
    "        file_name = line[0]             # 0 is where the file name is\n",
    "        label = line[5]                # 36 is where the Wearing_Hat label is\n",
    "\n",
    "        file_names.append(file_name)    # ADDING FILE NAME TO LIST\n",
    "        labels.append(label)            # ADDING LABEL TO LIST  \n",
    "# Load the images and the labels\n",
    "images = []\n",
    "for file_name in file_names:\n",
    "    image_path = f\"{image_dataset_directory}\\{file_name}\"\n",
    "    img = cv2.imread(image_path, 0) # Grayscale read, shouldn't need color for hat detection\n",
    "    images.append(img)\n",
    "\n",
    "images = np.array(images)\n",
    "images = images / 255.0 # Normalize to 0 to 1\n",
    "labels_pre = np.array(labels)\n",
    "labels = [1 if label == '1' else -1 for label in labels_pre] # NO string format\n",
    "labels = np.array(labels)\n",
    "# Replacing -1 label with 0 label\n",
    "for index, value in enumerate(labels):\n",
    "    if value == -1:\n",
    "        labels[index] = 0\n",
    "\n",
    "'''\n",
    "images --> all images as grayscale in matrix format\n",
    "labels --> all labels as 0 for bald and 1 for hair\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Data: Images[0]: \n",
      "[[0.91372549 0.91372549 0.91372549 ... 0.90980392 0.94509804 0.94509804]\n",
      " [0.91372549 0.91372549 0.91372549 ... 0.91764706 0.94509804 0.94509804]\n",
      " [0.91372549 0.91372549 0.91372549 ... 0.9254902  0.94901961 0.94901961]\n",
      " ...\n",
      " [0.34509804 0.24705882 0.36470588 ... 0.28235294 0.28627451 0.28627451]\n",
      " [0.30196078 0.33333333 0.44313725 ... 0.25882353 0.26666667 0.26666667]\n",
      " [0.45098039 0.59215686 0.75294118 ... 0.25882353 0.26666667 0.26666667]]\n",
      "Example Data: Labels\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# images --> a 10000 length list where each item is a array with gray scale values normalized 0 to 1\n",
    "# labels --> a 10000 length list where each index is 1 or -1 corresponding to images\n",
    "image_shape = np.shape(images) # (10000, 218, 178)\n",
    "label_shape = np.shape(labels) # (10000,)\n",
    "input_shape = (image_shape[1], image_shape[2], 1)\n",
    "print(\"Example Data: Images[0]: \")\n",
    "print(images[0])\n",
    "print(\"Example Data: Labels\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 216, 176, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 108, 88, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 106, 86, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 53, 43, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 51, 41, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 25, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4096064   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,192,961\n",
      "Trainable params: 4,192,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First Testing Model\n",
    "\n",
    "model = tf.keras.Sequential ([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape = (218, 178, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2,)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 274s 341ms/step - loss: 0.0652 - accuracy: 0.9769 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 263s 328ms/step - loss: 0.0578 - accuracy: 0.9771 - val_loss: 0.0586 - val_accuracy: 0.9785\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 264s 331ms/step - loss: 0.0470 - accuracy: 0.9810 - val_loss: 0.0526 - val_accuracy: 0.9803\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 262s 328ms/step - loss: 0.0397 - accuracy: 0.9847 - val_loss: 0.0511 - val_accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 261s 326ms/step - loss: 0.0349 - accuracy: 0.9871 - val_loss: 0.0616 - val_accuracy: 0.9795\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 260s 326ms/step - loss: 0.0272 - accuracy: 0.9889 - val_loss: 0.0594 - val_accuracy: 0.9808\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 260s 325ms/step - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.0580 - val_accuracy: 0.9810\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 261s 326ms/step - loss: 0.0183 - accuracy: 0.9926 - val_loss: 0.0756 - val_accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 261s 326ms/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.0997 - val_accuracy: 0.9780\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 261s 326ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.1056 - val_accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train Model\n",
    "    model.fit(images, labels, batch_size = 20, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 216, 176, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 108, 88, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 106, 86, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 53, 43, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 53, 43, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 51, 41, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 25, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64000)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4096064   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,192,961\n",
      "Trainable params: 4,192,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# including dropout within convolutional layers and dense layers\n",
    "# First Testing Model\n",
    "\n",
    "model = tf.keras.Sequential ([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape = (218, 178, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2,)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train Model\n",
    "    model.fit(images, labels, batch_size = 20, epochs = 10, validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
