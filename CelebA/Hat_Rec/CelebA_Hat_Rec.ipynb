{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA Dataset\n",
    "\n",
    "### File Characteristics\n",
    "\n",
    "img_align_celeba (sized images)\n",
    " - 202,599 images\n",
    "\n",
    "identity_CelebA\n",
    " - ALL lines: imge_id.jpg (ex. 000001.jpg) person_id\n",
    "\n",
    "list_attr_celeba\n",
    " - 1st line: number of images\n",
    " - 2nd line: Categories\n",
    " - 3rd+ lines: imge_id.jpg (ex. 000001.jpg) 1 or -1 for each category\n",
    "\n",
    "list_landmarks_align_celeba\n",
    " - 1st line: number of images\n",
    " - 2nd line: categories (ie. lefteye_x righteye_x etc)\n",
    " - 3rd_ lines: img_id.jpg (ex. 000001.jpg) number for position\n",
    "\n",
    "#### File Links\n",
    "Image Dataset: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\"\n",
    "\n",
    "Identity Annotations: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\identity_CelebA.txt\"\n",
    "\n",
    "Attribute Annoatations: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\list_attr_celeba.txt\"\n",
    "\n",
    "Landmark Location Annotations: \"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\list_landmarks_align_celeba.txt\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Image, Grey Scale\n",
      "(218, 178)\n",
      "[[233 233 233 ... 232 241 241]\n",
      " [233 233 233 ... 234 241 241]\n",
      " [233 233 233 ... 236 242 242]\n",
      " ...\n",
      " [ 88  63  93 ...  72  73  73]\n",
      " [ 77  85 113 ...  66  68  68]\n",
      " [115 151 192 ...  66  68  68]]\n"
     ]
    }
   ],
   "source": [
    "# Example opening one image in greyscale\n",
    "image = cv2.imread(r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\\000001.jpg\", 0)\n",
    "\n",
    "# The 2D Matrix of the image values. \n",
    "npimage = np.array(image)\n",
    "np.set_printoptions()\n",
    "print(\"First Image, Grey Scale\")\n",
    "print(np.shape(npimage))\n",
    "print(npimage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing up the dataset (Priminary)\n",
    "Total image count: 202,599\n",
    "\n",
    "Preliminary Training:   000001.jpg - 010000.jpg Count: 10,000 <br>\n",
    "\n",
    "Image dimensions 178 x 218\n",
    "\n",
    "First goal: Hat Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hat detection\n",
    "# Wearing Hat is at 35 index in second row\n",
    "# Wearing Hat is at 36 index (with first value being the ID of the image)\n",
    "# Total of 40 Attributes, Example Row:\n",
    "# ['000001.jpg' '-1' '1' '1' '-1' '-1' '-1' '-1' '-1' '-1' '-1' '-1' '1' '-1' '-1' '-1' '-1' '-1' '-1' '1' '1' '-1' '1' '-1' '-1' '1' '-1' '-1' '1' '-1' '-1' '-1' '1' '1' '-1' '1' '-1' '1' '-1' '-1' '1']\n",
    "# CSV File format\n",
    "# *     Label 1     Label 2     ...     Label n\n",
    "# imgID value 1     value 2     ...     value n\n",
    "# imgID value 1     value 2     ...     value n\n",
    "labels_csv_path = r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\CELEBA_annotations\\list_attr_celeba_CSV.csv\"   # CSV File created with celeb attributes .txt file\n",
    "image_dataset_directory = r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\MLData\\CELEBA_dataset\\img_align_celeba\"                      # File path to image dataset\n",
    "\n",
    "# open csv and read the file names and labels\n",
    "with open(labels_csv_path, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader) # skip first header row\n",
    "\n",
    "    # Create lists to store file names and labels\n",
    "    file_names = []\n",
    "    labels = []\n",
    "\n",
    "    for i, line in enumerate(reader):\n",
    "        if i>= 20000:                   # The first 10000 values\n",
    "            break\n",
    "\n",
    "        file_name = line[0]             # 0 is where the file name is\n",
    "        label = line[36]                # 36 is where the Wearing_Hat label is\n",
    "\n",
    "        file_names.append(file_name)    # ADDING FILE NAME TO LIST\n",
    "        labels.append(label)            # ADDING LABEL TO LIST  \n",
    "# Load the images and the labels\n",
    "images = []\n",
    "for file_name in file_names:\n",
    "    image_path = f\"{image_dataset_directory}\\{file_name}\"\n",
    "    img = cv2.imread(image_path, 0) # Grayscale read, shouldn't need color for hat detection\n",
    "    images.append(img)\n",
    "\n",
    "images = np.array(images)\n",
    "images = images / 255.0 # Normalize to 0 to 1\n",
    "labels_pre = np.array(labels)\n",
    "labels = [1 if label == '1' else -1 for label in labels_pre] # NO string format\n",
    "labels = np.array(labels)\n",
    "for index, value in enumerate(labels):\n",
    "    if value == -1:\n",
    "        labels[index] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Data: Images[0]: \n",
      "[[0.91372549 0.91372549 0.91372549 ... 0.90980392 0.94509804 0.94509804]\n",
      " [0.91372549 0.91372549 0.91372549 ... 0.91764706 0.94509804 0.94509804]\n",
      " [0.91372549 0.91372549 0.91372549 ... 0.9254902  0.94901961 0.94901961]\n",
      " ...\n",
      " [0.34509804 0.24705882 0.36470588 ... 0.28235294 0.28627451 0.28627451]\n",
      " [0.30196078 0.33333333 0.44313725 ... 0.25882353 0.26666667 0.26666667]\n",
      " [0.45098039 0.59215686 0.75294118 ... 0.25882353 0.26666667 0.26666667]]\n",
      "Example Data: Labels\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# images --> a 10000 length list where each item is a array with gray scale values normalized 0 to 1\n",
    "# labels --> a 10000 length list where each index is 1 or -1 corresponding to images\n",
    "image_shape = np.shape(images) # (10000, 218, 178)\n",
    "label_shape = np.shape(labels) # (10000,)\n",
    "input_shape = (image_shape[1], image_shape[2], 1)\n",
    "print(\"Example Data: Images[0]: \")\n",
    "print(images[0])\n",
    "print(\"Example Data: Labels\")\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 216, 176, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 108, 88, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 106, 86, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 53, 43, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 51, 41, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 25, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2048064   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,103,873\n",
      "Trainable params: 2,103,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create CNN Model Architecutre\n",
    "\n",
    "model = tf.keras.Sequential ([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape = (218, 178, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2,)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 263s 327ms/step - loss: 0.0934 - accuracy: 0.9700 - val_loss: 0.0799 - val_accuracy: 0.9745\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 240s 300ms/step - loss: 0.0607 - accuracy: 0.9784 - val_loss: 0.0716 - val_accuracy: 0.9743\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 229s 286ms/step - loss: 0.0503 - accuracy: 0.9818 - val_loss: 0.0748 - val_accuracy: 0.9780\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 231s 289ms/step - loss: 0.0379 - accuracy: 0.9853 - val_loss: 0.0971 - val_accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 225s 282ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 0.0811 - val_accuracy: 0.9768\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 221s 276ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.1113 - val_accuracy: 0.9755\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 220s 275ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.1027 - val_accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 221s 276ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.1219 - val_accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 221s 276ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.1699 - val_accuracy: 0.9735\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 220s 275ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.4001 - val_accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x207b10f59d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(images, labels, batch_size = 20, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\Saved_Models\\CelebA Project\\first_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 214, 174, 32)      832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 107, 87, 32)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 105, 85, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 52, 42, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 50, 40, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 25, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 23, 18, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 11, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 7, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 4, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                49216     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,713\n",
      "Trainable params: 151,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# More Layers\n",
    "# Changes Made --> \n",
    "# First Filter layer is now 5 by 5\n",
    "# Added a Convolutional layer\n",
    "model = tf.keras.Sequential ([\n",
    "    layers.Conv2D(32, (5, 5), activation='relu', input_shape = (218, 178, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2,)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2,)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2,)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 193s 239ms/step - loss: 0.1332 - accuracy: 0.9591 - val_loss: 0.1010 - val_accuracy: 0.9703\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 198s 248ms/step - loss: 0.0798 - accuracy: 0.9736 - val_loss: 0.0758 - val_accuracy: 0.9728\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 194s 243ms/step - loss: 0.0667 - accuracy: 0.9771 - val_loss: 0.0683 - val_accuracy: 0.9770\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 192s 240ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 0.0831 - val_accuracy: 0.9762\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 193s 241ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0731 - val_accuracy: 0.9735\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 194s 242ms/step - loss: 0.0458 - accuracy: 0.9843 - val_loss: 0.0607 - val_accuracy: 0.9805\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 190s 237ms/step - loss: 0.0388 - accuracy: 0.9861 - val_loss: 0.0991 - val_accuracy: 0.9785\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 188s 235ms/step - loss: 0.0366 - accuracy: 0.9875 - val_loss: 0.0599 - val_accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 189s 236ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0761 - val_accuracy: 0.9790\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 189s 237ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0881 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e2b212850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(images, labels, batch_size = 20, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\Saved_Models\\CelebA Project\\CelebA_Hat_Rec_02_2_more_layers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 216, 176, 64)      640       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 108, 88, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 106, 86, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 53, 43, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 51, 41, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 25, 20, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 23, 18, 512)       1180160   \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 11, 9, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 9, 7, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 4, 3, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6144)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1024)              6292480   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,727,425\n",
      "Trainable params: 10,727,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# More Layers\n",
    "# Changes Made --> \n",
    "# First Filter layer is now 5 by 5\n",
    "# Added a Convolutional layer\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(218, 178, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 712s 888ms/step - loss: 0.2123 - accuracy: 0.9504 - val_loss: 0.2071 - val_accuracy: 0.9477\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 718s 898ms/step - loss: 0.2020 - accuracy: 0.9509 - val_loss: 0.2065 - val_accuracy: 0.9477\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 720s 900ms/step - loss: 0.1996 - accuracy: 0.9509 - val_loss: 0.2086 - val_accuracy: 0.9477\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 736s 919ms/step - loss: 0.2000 - accuracy: 0.9509 - val_loss: 0.2082 - val_accuracy: 0.9477\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 727s 909ms/step - loss: 0.1995 - accuracy: 0.9509 - val_loss: 0.2068 - val_accuracy: 0.9477\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 721s 902ms/step - loss: 0.1999 - accuracy: 0.9509 - val_loss: 0.2080 - val_accuracy: 0.9477\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 713s 892ms/step - loss: 0.1989 - accuracy: 0.9509 - val_loss: 0.2063 - val_accuracy: 0.9477\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 694s 868ms/step - loss: 0.1990 - accuracy: 0.9509 - val_loss: 0.2051 - val_accuracy: 0.9477\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 688s 860ms/step - loss: 0.1983 - accuracy: 0.9509 - val_loss: 0.2053 - val_accuracy: 0.9477\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 697s 871ms/step - loss: 0.1976 - accuracy: 0.9509 - val_loss: 0.2120 - val_accuracy: 0.9477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e2b23fcd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(images, labels, batch_size = 20, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(r\"C:\\Users\\johns\\OneDrive\\Desktop\\ML\\Saved_Models\\CelebA Project\\CelebA_Hat_Rec_03_large_10000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
